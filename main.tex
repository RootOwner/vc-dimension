\documentclass[12pt,a4paper]{article}


% -----------------------------
% Библиография (ГОСТ)
% -----------------------------
\usepackage[
  backend=biber,
  style=gost-numeric,
  language=auto,
  autolang=other,
  sorting=nyt,
  maxbibnames=5,
  minbibnames=3
]{biblatex}

\addbibresource{references.bib}




% ---------- Кодировка и язык ----------
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}

% ---------- Геометрия страницы ----------
\usepackage[
    left=30mm,
    right=20mm,
    top=20mm,
    bottom=20mm
]{geometry}

% ---------- Интервалы ----------
\usepackage{setspace}
\onehalfspacing

% ---------- Для пустых страниц ----------
\usepackage{afterpage}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{csquotes}
\usepackage[expansion=false]{microtype}  % Улучшает микротипографику
\sloppy                 % Разрешает LaTeX быть менее строгим к переносам

\begin{document}

% ================= ТИТУЛЬНЫЙ ЛИСТ =================
\thispagestyle{empty}

\begin{center}
Санкт-Петербургский государственный университет

\vspace{0.5cm}

Прикладная математика, программирование и искусственный интеллект
\end{center}

\vfill

\begin{center}
Отчёт по учебной практике 1 (научно-исследовательской работе) (семестр 1)

\vspace{0.5cm}

\textbf{VC-размерность и ёмкость нейросетей: \\
от классики к norm-based оценкам и margin-границам}
\end{center}

\vfill

\begin{flushright}
Выполнил:

Бокиев Бахромжон Боходир угли,

группа 25.Б21-мм

\vspace{0.3cm} % Небольшой отступ перед подписью
\includegraphics[width=3cm, height=1cm]{signature_student.jpg}

\vspace{1.2cm} % Оставляем место для подписи научрука

Научный руководитель:

кандидат физ.-мат. наук, доцент

Мокаев Тимур Назирович

Кафедра прикладной кибернетики

\vspace{0.3cm} % Небольшой отступ перед подписью
\includegraphics[width=3cm, height=1cm]{signature_supervisor.jpg}
\end{flushright}

\vfill

\begin{center}
Работа (коментария) и заслуживает оценки (зачтено/не зачтено) (оценка (...))
\end{center}

\vfill

\begin{center}
Санкт-Петербург

2025
\end{center}

\newpage
% =================================================





% ================= ОГЛАВЛЕНИЕ =================

% начинаем нумерацию страниц,
% но титульный лист уже считается как страница 1
\setcounter{page}{2}

\tableofcontents
\thispagestyle{plain}

\newpage
% ===============================================


% дальше пойдут основные разделы
% (Введение, Постановка задачи и т.д.)





\section{Введение}

Современные методы машинного обучения, и в частности глубокие нейронные сети,
демонстрируют высокую эффективность в задачах классификации, распознавания образов
и анализа данных. При этом на практике широко наблюдается феномен, противоречащий
классическим представлениям статистической теории обучения: модели с числом
параметров, существенно превышающим объём обучающей выборки, способны не только
достигать нулевой обучающей ошибки, но и успешно обобщать на новых данных.
Данный эффект получил название \emph{парадокса переобучения} и является одной из
ключевых теоретических проблем современного машинного обучения.

Классическая теория обучения связывает способность модели к обобщению с её
сложностью, измеряемой через комбинаторные характеристики, такие как
VC-размерность, псевдоразмерность и функция роста. Для широких классов моделей
эти величины позволяют получить априорные оценки обобщающей ошибки, зависящие
от размера обучающей выборки. Однако для глубоких нейронных сетей классические
оценки VC-размерности, выражаемые через число параметров, оказываются чрезмерно
грубыми и зачастую не отражают реального поведения моделей на практике.

В последние годы были предложены альтернативные подходы к оценке ёмкости
нейросетевых моделей, основанные не только на количестве параметров, но и на
геометрических свойствах реализуемых классификаторов. Существенную роль в этих
подходах играют \emph{маржин-границы}, а также \emph{norm-based оценки сложности},
использующие спектральные и фробениусовы нормы весовых матриц слоёв. Эти методы
позволяют связать обобщающую способность сети с её липшицевой константой и
устойчивостью к малым возмущениям входных данных, что даёт более тонкое описание
реальной сложности модели.

Особый интерес представляют теоретические результаты, связывающие маржин
классификатора с радиемахеровой сложностью соответствующего функционального класса.
В линейном случае такие оценки хорошо изучены и дают наглядную интерпретацию:
при фиксированной норме весов увеличение маржи приводит к уменьшению верхней
оценки обобщающей ошибки. Для глубоких нейронных сетей аналогичные результаты
получаются при замене нормы весового вектора на произведение спектральных норм
слоёв, что позволяет перенести маржинный анализ на многослойные архитектуры.

Целью данной работы является изучение классических и современных подходов к
оценке ёмкости нейронных сетей, а также анализ связи между параметрическими,
комбинаторными и геометрическими мерами сложности моделей. Особое внимание
уделяется norm-based и маржин-ориентированным границам обобщающей ошибки и их
практической интерпретации.

Для достижения поставленной цели в работе решаются следующие задачи:
\begin{itemize}
    \item рассмотреть основные определения и результаты теории VC-размерности и
    радиемахеровой сложности в задаче классификации;
    \item изложить маржин-оценки обобщающей ошибки для линейных классификаторов;
    \item показать перенос маржинного анализа на глубокие нейронные сети с
    использованием спектральных норм слоёв;
    \item реализовать воспроизводимые вычислительные эксперименты для оценки
    маржи и norm-based характеристик нейросетей;
    \item проанализировать связь между полученными теоретическими оценками и
    эмпирическими результатами обобщения.
\end{itemize}

Практическая значимость работы заключается в том, что рассмотренные подходы
позволяют лучше понять механизмы обобщения глубоких нейронных сетей и дают
теоретические основания для применения регуляризации, основанной на контроле
норм весов и маржи классификатора.



%==============================================================================
%(Постановка задачи)


\section{Постановка задачи}

Рассматривается задача бинарной классификации в стандартной постановке
статистического обучения. Пусть
\[
\mathcal{S} = \{(x_i, y_i)\}_{i=1}^{n}, \quad x_i \in \mathcal{X} \subseteq \mathbb{R}^d,
\quad y_i \in \{-1, +1\},
\]
— обучающая выборка, состоящая из независимых и одинаково распределённых
наблюдений, сгенерированных по неизвестному распределению
$\mathcal{D}$ на пространстве $\mathcal{X} \times \{-1, +1\}$.

\subsection*{Классификатор и ошибка обобщения}

Классификатором называется отображение
\[
f : \mathcal{X} \rightarrow \mathbb{R},
\]
решающее правило которого определяется знаком значения $f(x)$.
Фактическое предсказание на объекте $x$ задаётся как
$\mathrm{sign}(f(x))$.

\emph{Истинной (обобщающей) ошибкой} классификатора $f$ называется вероятность
неверной классификации:
\[
\mathcal{L}(f) = \mathbb{P}_{(x,y)\sim\mathcal{D}}\bigl( y f(x) \le 0 \bigr).
\]
На практике распределение $\mathcal{D}$ неизвестно, поэтому вместо
$\mathcal{L}(f)$ используется эмпирическая оценка ошибки на конечной выборке.

\subsection*{Функциональный класс и меры сложности}

Пусть $\mathcal{F}$ — класс функций, реализуемых выбранной архитектурой
нейронной сети с фиксированной структурой, но произвольными весовыми
параметрами. Способность класса $\mathcal{F}$ к обобщению традиционно
характеризуется его \emph{ёмкостью}, измеряемой с помощью различных мер
сложности.

\paragraph{VC-размерность.}
VC-размерностью класса $\mathcal{F}$ называется наибольшая мощность множества
точек, которое может быть \emph{разбито} (shattered) функциями из
$\mathcal{F}$. Данная характеристика отражает комбинаторную сложность
функционального класса и используется для получения априорных оценок
обобщающей ошибки.

\paragraph{Радемахерова сложность.}
Эмпирическая радемахерова сложность класса $\mathcal{F}$ на выборке
$\mathcal{S}$ определяется как
\[
\widehat{\mathfrak{R}}_{\mathcal{S}}(\mathcal{F}) =
\mathbb{E}_{\sigma}
\left[
\sup_{f \in \mathcal{F}}
\frac{1}{n}
\sum_{i=1}^{n}
\sigma_i f(x_i)
\right],
\]
где $\sigma_i$ — независимые случайные величины, равномерно распределённые
на множестве $\{-1, +1\}$. Радемахерова сложность позволяет получать
данные-зависимые оценки обобщающей ошибки и широко используется в анализе
маржинных границ.

\paragraph{Маржин.}
Для классификатора $f$ маржином на объекте $(x_i, y_i)$ называется величина
$y_i f(x_i)$. Минимальный эмпирический маржин на выборке $\mathcal{S}$
определяется как
\[
\gamma_{\mathcal{S}}(f) = \min_{1 \le i \le n} y_i f(x_i).
\]
Величина маржина отражает устойчивость классификатора к возмущениям входных
данных и играет ключевую роль в современных оценках обобщающей способности
моделей.

\paragraph{Norm-based меры сложности.}
Для глубоких нейронных сетей существенное значение имеют оценки сложности,
основанные на нормах весовых матриц слоёв. В частности, рассматриваются
спектральные нормы $\|W_\ell\|_2$ и фробениусовы нормы $\|W_\ell\|_F$
матриц весов слоёв $W_\ell$, $\ell = 1, \dots, L$. На их основе вводятся
прокси-меры сложности, зависящие от произведения спектральных норм слоёв и
отражающие липшицеву константу реализуемого отображения.

\subsection*{Критерии качества}

Для оценки качества классификаторов в работе используются следующие
характеристики:
\begin{itemize}
    \item \emph{эмпирическая ошибка} и точность классификации (accuracy) на
    обучающей и тестовой выборках;
    \item минимальный и средний эмпирический маржин классификатора;
    \item norm-based прокси-меры сложности, основанные на спектральных и
    фробениусовых нормах весовых матриц слоёв нейронной сети.
\end{itemize}

Основной задачей работы является анализ взаимосвязи между перечисленными
мерами сложности и эмпирическим качеством обобщения нейросетевых моделей при
фиксированном числе параметров.



%==============================================================================
%(Обзор литературы)


\section{Обзор литературы}

В данном разделе рассматриваются основные теоретические результаты,
связанные с оценкой ёмкости моделей машинного обучения и анализом их
обобщающей способности. Обзор построен от классических комбинаторных
подходов к современным norm-based и маржин-ориентированным оценкам,
применимым к глубоким нейронным сетям.

\subsection{Классическая теория обучения и VC-размерность}

В рамках статистической теории обучения способность модели к обобщению
традиционно связывается с ёмкостью соответствующего функционального класса.
Ключевую роль в этом контексте играет VC-размерность, введённая Вапником и
Червоненкисом~\cite{vapnik1995nature,vapnik1998statistical}, а также связанные
с ней понятия функции роста и комбинаторных границ обобщающей ошибки.

В классической статистической теории обучения анализ обобщающей способности
модели основывается на изучении свойств функционального класса, из которого
выбирается классификатор. Основная идея заключается в том, что способность
модели подстраиваться под обучающую выборку должна контролироваться
некоторой мерой сложности, не зависящей от конкретной реализации алгоритма
обучения~\cite{vapnik1998statistical,shalev2014understanding}.

Одной из центральных характеристик ёмкости функционального класса является
VC-размерность, введённая Вапником и Червоненкисом~\cite{vapnik1995nature}.
Интуитивно VC-размерность измеряет способность класса функций реализовывать
произвольные бинарные разметки на конечных наборах точек. Формально,
VC-размерностью класса $\mathcal{F}$ называется наибольшее целое число $d$,
для которого существует набор из $d$ различных точек, разбиваемый
(shattered) функциями из $\mathcal{F}$, то есть такой, что для любой бинарной
разметки этих точек найдётся функция $f \in \mathcal{F}$, согласующаяся с
данной разметкой~\cite{anthony1999neural,vapnik1998statistical}.

VC-размерность тесно связана с понятием функции роста, которая характеризует
максимальное число различных бинарных классификаций, реализуемых классом
$\mathcal{F}$ на выборке фиксированного размера. Фундаментальным результатом
в этой области является лемма Саура–Шелая, устанавливающая верхнюю оценку
функции роста через VC-размерность~\cite{vapnik1998statistical}.
В частности, если VC-размерность класса $\mathcal{F}$ равна $d$, то число
различных разметок, реализуемых на выборке из $n$ точек, растёт не быстрее
полинома степени $d$ по $n$~\cite{shalev2014understanding}.

Используя лемму Саура–Шелая и стандартные вероятностные неравенства, в рамках
классической теории обучения получаются априорные оценки обобщающей ошибки,
зависящие от VC-размерности функционального класса и объёма обучающей
выборки~\cite{vapnik1998statistical,shalev2014understanding}.
Эти оценки показывают, что при фиксированной сложности модели увеличение
размера выборки приводит к уменьшению разрыва между эмпирической и истинной
ошибкой классификации.

Несмотря на фундаментальную роль VC-размерности, данный подход обладает
существенными ограничениями. Во-первых, VC-оценки носят асимптотический и
зачастую избыточно грубый характер, что делает их слабо применимыми для
практического анализа конкретных моделей~\cite{anthony1999neural}.
Во-вторых, VC-размерность рассматривает функциональный класс в целом и не
учитывает геометрические свойства отдельных классификаторов, такие как
величина маржина или нормы параметров~\cite{shalev2014understanding}.
Эти ограничения особенно ярко проявляются при анализе глубоких нейронных
сетей, для которых классические VC-оценки часто оказываются чрезмерно
завышенными.





% TODO:
% - Определение VCdim
% - Теорема Саура–Шелая
% - Классические bounds на ошибку
% - Ограничения VC-подхода для нейросетей
\subsection{VC-размерность нейронных сетей}

Применение VC-размерности к анализу нейронных сетей приводит к оценкам,
зависящим от числа параметров и глубины архитектуры~\cite{goldberg1995bounding}.
Для сетей с
кусочно-линейными функциями активации были получены почти точные
асимптотические оценки VC-размерности, уточняющие зависимость от структуры
модели~\cite{harvey2017nearly}.

Применение классического аппарата VC-размерности к нейронным сетям долгое
время оставалось нетривиальной задачей, поскольку функциональные классы,
реализуемые многослойными архитектурами, обладают сложной иерархической
структурой. Ранние оценки VC-размерности нейросетей, как правило, выражались
через грубые верхние границы, зависящие от числа параметров, и не отражали
влияния глубины архитектуры~\cite{goldberg1995bounding}.

Существенный прогресс в этом направлении был достигнут для сетей с
кусочно-линейными функциями активации, такими как ReLU. Для данного класса
моделей были получены почти точные (nearly-tight) асимптотические оценки
VC-размерности, выраженные через общее число параметров $W$ и глубину сети
$L$~\cite{harvey2017nearly}. В частности, было показано, что VC-размерность
таких сетей растёт приблизительно линейно по $W$ и $L$ с дополнительным
логарифмическим множителем~\cite{bartlett1998almost}.

Интуитивно линейная зависимость от числа параметров обусловлена тем, что
каждый вес вносит дополнительную степень свободы в реализуемый класс
функций. Зависимость от глубины отражает композиционную структуру нейронной
сети: увеличение числа слоёв позволяет реализовывать более сложные
кусково-линейные разбиения входного пространства. При этом логарифмический
множитель возникает как следствие оценки функции роста и использования
комбинаторных аргументов, связывающих количество возможных знаковых
конфигураций с числом параметров модели~\cite{bartlett1998almost,harvey2017nearly}.

Несмотря на теоретическую значимость nearly-tight оценок, их практическая
применимость остаётся ограниченной. Во-первых, получаемые верхние границы
зачастую существенно превосходят реальные размеры обучающих выборок, что
делает соответствующие оценки обобщающей ошибки тривиальными. Во-вторых,
VC-размерность характеризует функциональный класс в целом и не учитывает
конкретное положение обученного классификатора внутри этого класса~\cite{goldberg1995bounding}. В
результате модели с одинаковым числом параметров и глубиной, но различной
структурой весов, имеют одинаковую VC-размерность, несмотря на возможные
существенные различия в их обобщающей способности.

Таким образом, хотя оценки VC-размерности нейронных сетей дают важное
понимание асимптотической сложности моделей, они не объясняют наблюдаемую
на практике способность переобученных сетей успешно обобщать~\cite{harvey2017nearly}.
Это
обстоятельство мотивирует переход к более тонким мерам сложности, которые
учитывают геометрические свойства классификаторов и зависят от конкретных
значений параметров, а не только от их количества.


% TODO:
% - Результаты Bartlett et al. (2019)
% - Зависимость VCdim от W и L
% - Роль log-фактора
% - Ограниченность интерпретации на практике


\subsection{Norm-based подходы к оценке сложности моделей}

Альтернативой комбинаторным характеристикам являются подходы, основанные на
анализе норм параметров модели. В частности, norm-based оценки сложности
используют спектральные и фробениусовы нормы весовых матриц нейронной сети
и позволяют связать обобщающую способность модели с её липшицевыми
свойствами~\cite{mohri2018foundations}.

Ограничения классических комбинаторных характеристик, таких как VC-размерность,
стимулировали развитие альтернативных подходов к оценке ёмкости моделей,
учитывающих конкретные значения параметров обученного классификатора. В этом
контексте широкое распространение получили norm-based методы, в которых
сложность модели оценивается через нормы весовых параметров, а не через их
количество~\cite{bartlett2002rademacher,koltchinskii2002rademacher}.

Для нейронных сетей особое значение имеют спектральные и фробениусовы нормы
матриц весов слоёв. Спектральная норма матрицы $W_\ell$, обозначаемая
$\|W_\ell\|_2$, равна её наибольшему сингулярному значению и характеризует
максимальное растяжение пространства при линейном преобразовании. Фробениусова
норма $\|W_\ell\|_F$ отражает суммарную энергию параметров слоя и связана с
размером весовой матрицы~\cite{mohri2018foundations}.

Ключевым наблюдением norm-based подходов является связь норм весовых матриц с
липшицевой константой нейронной сети. Для многослойной сети с
1-липшицевыми функциями активации липшицева константа по входу может быть
оценена сверху произведением спектральных норм слоёв. Данная величина
характеризует чувствительность выходного сигнала сети к малым возмущениям
входных данных и, следовательно, устойчивость классификатора%
~\cite{bartlett2002rademacher,mohri2018foundations}.

Использование norm-based характеристик позволяет учитывать геометрические
свойства реализуемых функций и различать классификаторы с одинаковым числом
параметров, но различной структурой весов. Это особенно важно для глубоких
нейронных сетей, в которых регуляризация, ограничивающая нормы весов, может
существенно влиять на обобщающую способность модели при фиксированной
архитектуре~\cite{koltchinskii2002rademacher,mohri2018foundations}.

Современные теоретические результаты показывают, что комбинация произведения
спектральных норм и дополнительных факторов, зависящих от фробениусовых норм
слоёв, приводит к практически интерпретируемым прокси-мерам сложности. Эти
величины естественным образом возникают в оценках обобщающей ошибки, полученных
через маржинный анализ и радиемахерову сложность, и обеспечивают более точное
описание поведения обученных нейросетей по сравнению с чисто комбинаторными
подходами~\cite{bartlett2017spectrally,neyshabur2015norm,golowich2018size}.


\subsection{Маржинные границы обобщающей ошибки}

Маржинный анализ играет важную роль в теоретическом обосновании
обобщающей способности классификаторов. Для линейных моделей маржинные
границы хорошо изучены и выражаются через норму весового вектора. Для
глубоких нейронных сетей аналогичные оценки получаются при использовании
norm-based прокси-мер сложности~\cite{bartlett2017spectrally,neyshabur2018pac}.

Маржинный анализ является одним из наиболее информативных инструментов
оценки обобщающей способности классификаторов. Для линейных моделей
классификация основывается на знаке линейной функции, а маржином называется
минимальное расстояние обучающих примеров до разделяющей гиперплоскости.
Интуитивно большой маржин означает устойчивость классификатора к малым
возмущениям данных и, как следствие, лучшую способность к обобщению.

В классическом случае линейных классификаторов маржинные границы
обобщающей ошибки выражаются через норму весового вектора и радиус входных
данных. Такие оценки показывают, что при фиксированном маржине увеличение
нормы параметров приводит к ухудшению обобщающей способности, что
обосновывает использование нормовой регуляризации в алгоритмах обучения.

Связь маржинного анализа с радиемахеровой сложностью позволяет распространить
данный подход на более общие функциональные классы. Радиемахерова сложность
характеризует способность класса функций аппроксимировать случайные шумовые
метки и, в отличие от VC-размерности, учитывает геометрические свойства
функций~\cite{bartlett2002rademacher,koltchinskii2002rademacher}.

Использование маржинных оценок в сочетании с радиемахеровой
сложностью приводит к верхним границам обобщающей ошибки, зависящим от
конкретного положения классификатора внутри функционального класса.

Для глубоких нейронных сетей прямое использование маржинных границ
затруднено из-за их композиционной структуры. Тем не менее, при
использовании norm-based прокси-мер сложности удаётся получить обобщающие
оценки, в которых маржин входных данных сочетается с произведением
спектральных норм слоёв сети. Такие границы отражают как геометрическую
устойчивость классификатора, так и сложность реализуемой функции%
~\cite{bartlett2017spectrally,neyshabur2015norm}.

Маржинные границы для глубоких сетей демонстрируют, что высокая способность
к обобщению может сохраняться даже при переизбыточном числе параметров, при
условии контроля норм весов и обеспечения достаточно большого маржина.
Данный факт согласуется с эмпирическими наблюдениями и служит теоретическим
обоснованием эффективности современных методов регуляризации и нормализации,
используемых при обучении нейронных сетей, а также с современным пониманием
явления переparameterизации и double descent в машинном обучении%
~\cite{bartlett2017spectrally,neyshabur2018pac,neyshabur2015norm,golowich2018size,zhang2017rethinking,belkin2019reconciling}.


% TODO:
% - Margin bounds для линейных классификаторов
% - Связь с радиемахеровой сложностью
% - Перенос на глубокие сети
% - Spectrally-normalized margin bounds

\subsection{Выводы по обзору литературы}

Проведённый обзор показывает, что классические комбинаторные оценки
сложности, такие как VC-размерность, не всегда адекватно отражают
обобщающую способность современных нейросетевых моделей. В то же время
norm-based и маржин-ориентированные подходы позволяют получить более
тонкое и практически интерпретируемое описание сложности нейронных сетей,
что делает их перспективными как с теоретической, так и с прикладной точки
зрения~\cite{bartlett2017spectrally,neyshabur2018pac}.

Проведённый обзор литературы демонстрирует эволюцию теоретических подходов к
оценке сложности моделей машинного обучения и анализу их обобщающей
способности. Классическая статистическая теория обучения опирается на
комбинаторные характеристики функциональных классов, такие как
VC-размерность, позволяющие получить универсальные, но зачастую грубые
оценки обобщающей ошибки~\cite{bousquet2002stability,mcallester2003pac}.

Для нейронных сетей VC-размерность демонстрирует корректные асимптотические
свойства, однако не объясняет наблюдаемую на практике способность
переизбыточных моделей эффективно обобщать~\cite{zhang2017rethinking}.

Это обстоятельство мотивирует использование более тонких мер сложности,
зависящих от конкретных значений параметров обученного классификатора.

Norm-based подходы и маржинный анализ предоставляют такую возможность,
учитывая геометрические свойства реализуемых функций, устойчивость модели к
возмущениям данных и контроль липшицевой константы нейронной сети. Совмещение
маржинных характеристик с norm-based прокси-мерами сложности позволяет
получить теоретические оценки, лучше согласующиеся с эмпирическими
наблюдениями и практикой обучения глубоких нейронных сетей~\cite{bartlett2017spectrally,neyshabur2015norm}.

В связи с этим в данной работе в качестве основного инструмента анализа
обобщающей способности рассматриваются norm-based и маржин-ориентированные
подходы, которые далее используются при формулировке теоретических
результатов и постановке вычислительных экспериментов.


% TODO:
% - Сравнение подходов
% - Мотивация выбора norm-based анализа в данной работе



\section{Основной объект и методы исследования}

В данном разделе формализуется объект исследования, вводятся основные
теоретические понятия и излагаются методы анализа обобщающей способности
моделей классификации. Раздел включает определения используемых мер
сложности, вывод маржин-ориентированных оценок обобщающей ошибки, а также
описание вычислительной постановки, применяемой для практического анализа.

\subsection{Определения}

В этом подразделе вводятся основные понятия и обозначения, используемые
далее при формулировке теоретических результатов и вычислительных методов.
Целью является унификация терминологии и фиксация используемых мер
сложности моделей.


%В данном подразделе вводятся основные понятия и обозначения, используемые
%далее при формулировке теоретических результатов и вычислительных методов.
%Все определения приводятся в объёме, достаточном для последующего анализа,
%без детального воспроизведения известных доказательств.

\subsubsection{VC-размерность}

Пусть $\mathcal{F}$ — класс бинарных классификаторов, действующих на
пространстве признаков $\mathcal{X}$. Множество точек
$\{x_1, \dots, x_n\} \subset \mathcal{X}$ называют разбиваемым (shattered)
классом $\mathcal{F}$, если для любой бинарной разметки этих точек существует
функция $f \in \mathcal{F}$, согласующаяся с данной разметкой%
~\cite{vapnik1995nature,anthony1999neural,goldberg1995bounding}.

VC-размерностью класса $\mathcal{F}$ называется наибольшее целое число $d$,
для которого существует множество из $d$ точек, разбиваемое классом
$\mathcal{F}$. Если такие множества существуют для сколь угодно больших $d$, 
VC-размерность считается бесконечной. Эта величина используется как
комбинаторная мера ёмкости функционального класса%
~\cite{vapnik1998statistical,shalev2014understanding,goldberg1995bounding}.

\subsubsection{Функция роста}

Функцией роста класса $\mathcal{F}$ называют функцию $m_{\mathcal{F}}(n)$,
определяемую как максимальное число различных бинарных разметок, которые могут
быть реализованы функциями из $\mathcal{F}$ на выборке из $n$ точек%
~\cite{vapnik1998statistical,bartlett1998almost}. Функция роста характеризует
зависимость выразительной способности класса от размера выборки и служит
связующим звеном между VC-размерностью и оценками обобщающей ошибки%
~\cite{shalev2014understanding}.

При конечной VC-размерности функция роста ограничивается сверху полиномиальной
функцией от $n$, что лежит в основе классических обобщающих оценок
статистической теории обучения%
~\cite{vapnik1998statistical,anthony1999neural,bartlett1998almost}.

\subsubsection{Радиемахерова сложность}

Радиемахерова сложность является альтернативной мерой сложности
функционального класса, учитывающей его геометрические свойства%
~\cite{shalev2014understanding,bartlett1998almost,bartlett2002rademacher}.
Пусть $\mathcal{S} = \{x_1, \dots, x_n\}$ — обучающая выборка, а
$\sigma_1, \dots, \sigma_n$ — независимые радемахеровы случайные величины,
принимающие значения $\pm 1$ с равными вероятностями%
~\cite{shalev2014understanding,koltchinskii2002rademacher}.

Эмпирическая радемахерова сложность класса $\mathcal{F}$ на выборке
$\mathcal{S}$ определяется как
\[
\hat{\mathcal{R}}_{\mathcal{S}}(\mathcal{F}) =
\mathbb{E}_{\sigma}
\left[
\sup_{f \in \mathcal{F}}
\frac{1}{n} \sum_{i=1}^{n} \sigma_i f(x_i)
\right].
\]

Радиемахерова сложность измеряет способность класса функций аппроксимировать
случайные шумовые метки и используется для получения данных-зависимых оценок
обобщающей ошибки%
~\cite{shalev2014understanding,bartlett1998almost,bartlett2002rademacher,mohri2018foundations}.

\subsubsection{Маржин}

% TODO:
% - Определение маржина классификатора
% - Геометрическая интерпретация
% - Связь с устойчивостью модели

Рассмотрим классификатор $f : \mathcal{X} \to \mathbb{R}$ и обучающую выборку
$\{(x_i, y_i)\}_{i=1}^{n}$, где $y_i \in \{-1, +1\}$. Маржином классификатора
на объекте $x_i$ называется величина $y_i f(x_i)$, характеризующая степень
уверенности классификации%
~\cite{shalev2014understanding,vapnik1998statistical}.

Минимальный маржин на выборке определяется как
\[
\gamma = \min_{1 \leq i \leq n} y_i f(x_i).
\]
Большие значения маржина соответствуют более устойчивым классификаторам и
играют ключевую роль в маржинных оценках обобщающей способности%
~\cite{vapnik1998statistical,shalev2014understanding,harvey2017nearly}.
В случае
линейных моделей маржин напрямую связан с нормой весового вектора, а для
глубоких нейронных сетей — с norm-based характеристиками параметров.


\subsection{Маржин-ориентированные оценки обобщающей способности}

В данном подразделе формулируется и обсуждается маржин-ориентированный
теоретический результат, связывающий обобщающую ошибку классификатора с
расположением обучающих данных относительно разделяющей поверхности и
norm-based характеристиками сложности модели. Изложение построено от
линейных моделей к глубоким нейронным сетям.

\subsubsection{Маржинная граница для линейного классификатора}


Рассмотрим задачу бинарной классификации в евклидовом пространстве
$\mathbb{R}^d$. Пусть обучающая выборка имеет вид
$\{(x_i, y_i)\}_{i=1}^{n}$, где $x_i \in \mathbb{R}^d$ и
$y_i \in \{-1, +1\}$. Линейный классификатор задаётся функцией
$f_w(x) = \langle w, x \rangle$, где $w \in \mathbb{R}^d$ — вектор
параметров модели.

Маржином классификатора на объекте $x_i$ называется величина
$y_i \langle w, x_i \rangle$, характеризующая степень уверенности
классификации. Минимальный маржин на выборке определяется как
\[
\gamma = \min_{1 \leq i \leq n} y_i \langle w, x_i \rangle.
\]
Большой маржин означает, что все обучающие объекты находятся на
достаточном расстоянии от разделяющей гиперплоскости, что обеспечивает
устойчивость классификатора к малым возмущениям входных данных.

Классические результаты статистической теории обучения показывают, что
обобщающая ошибка линейного классификатора может быть ограничена сверху
величиной, зависящей от маржина, нормы весового вектора и геометрии
входных данных. В частности, при предположении ограниченности нормы
входных векторов $\|x_i\| \leq R$ вероятность ошибки на новых данных
убывает с ростом маржина и уменьшается при контроле нормы параметров
$\|w\|$.

Интерпретация маржинных границ подчёркивает, что обобщающая способность
модели определяется не только выразительностью функционального класса,
но и геометрическим положением конкретного классификатора внутри этого
класса. Данный факт объясняет эффективность методов обучения,
ориентированных на максимизацию маржина, таких как метод опорных
векторов, и служит отправной точкой для обобщения маржинного анализа на
более сложные модели.

В дальнейшем данная идея будет усилена с использованием радемахеровой
сложности, что позволит получить оценки обобщающей ошибки, зависящие от
данных и применимые к более общим функциональным классам.


% TODO:
% - Постановка линейной бинарной классификации
% - Определение функционального класса
% - Классическая маржинная оценка обобщающей ошибки
% - Интуитивная интерпретация результата

\subsubsection{Радиемахерова сложность и маржинные оценки}


Классические маржинные границы для линейных классификаторов могут быть
усилены с использованием радемахеровой сложности, которая предоставляет
данно-зависимую меру ёмкости функционального класса. В отличие от
VC-размерности, радемахерова сложность позволяет учитывать геометрические
свойства обучающей выборки и положение конкретного классификатора внутри
класса функций.

Рассмотрим класс линейных функций
\[
\mathcal{F} = \{ x \mapsto \langle w, x \rangle : \|w\| \leq B \}.
\]
Радиемахерова сложность данного класса зависит от нормы параметров и
эмпирических характеристик данных, в частности от среднего квадратичного
размера входных векторов. Это приводит к оценкам обобщающей ошибки, в которых
роль комбинаторной сложности заменяется контролем норм и статистическими
свойствами выборки.

Совмещение маржинного анализа с радемахеровой сложностью позволяет получить
границы обобщающей ошибки, зависящие от маржина классификатора и величины
$\hat{\mathcal{R}}_{\mathcal{S}}(\mathcal{F})$. Такие оценки обладают рядом
преимуществ по сравнению с VC-оценками. Во-первых, они являются
данно-зависимыми и адаптируются к конкретной выборке. Во-вторых, они
различают классификаторы с одинаковой архитектурой, но различными значениями
параметров, что особенно важно для переобученных моделей.

С точки зрения интерпретации, малая радемахерова сложность означает
ограниченную способность класса функций аппроксимировать случайный шум, а
большой маржин указывает на устойчивость классификатора к возмущениям
входных данных. Совместное использование этих характеристик позволяет
получить более точные и практически значимые оценки обобщающей способности.

Используемый подход естественным образом обобщается на более сложные
функциональные классы, включая глубокие нейронные сети. В этом случае
радемахерова сложность контролируется через norm-based прокси-меры
сложности, связанные с параметрами модели, что делает возможным перенос
маржинных оценок на композиционные архитектуры.


% TODO:
% - Использование радемахеровой сложности
% - Связь с маржинными bounds
% - Преимущества по сравнению с VC-оценками

\subsubsection{Перенос маржинных оценок на глубокие нейронные сети}

Перенос маржинных оценок обобщающей ошибки с линейных моделей на глубокие
нейронные сети является нетривиальной задачей вследствие композиционной
природы последних. В отличие от линейных классификаторов, нейронные сети
представляют собой последовательную композицию линейных преобразований и
нелинейных функций активации, что существенно усложняет анализ их
обобщающей способности~\cite{bartlett2017spectrally,gouk2021regularisation}.

Прямое применение маржинных границ, полученных для линейных моделей, к
глубоким сетям не учитывает накопление искажения сигнала при прохождении
через несколько слоёв. Малые возмущения входных данных могут усиливаться на
каждом этапе композиции, что приводит к потере контроля над устойчивостью
классификатора. В результате классические маржинные оценки перестают быть
информативными~\cite{golowich2018size}.

Ключевым инструментом для преодоления данной проблемы является анализ
липшицевых свойств нейронной сети. Липшицева константа характеризует
чувствительность выхода модели к изменениям входа и позволяет количественно
оценить накопление искажения при композиции слоёв. Для сети, состоящей из
последовательности функций, липшицева константа всей модели может быть
оценена через произведение липшицевых констант отдельных слоёв~\cite{gouk2021regularisation}.

При использовании 1-липшицевых функций активации, таких как ReLU, основную
роль в контроле липшицевой константы играют линейные преобразования,
определяемые весовыми матрицами слоёв. Это наблюдение позволяет связать
устойчивость глубокого классификатора с нормами параметров сети и тем самым
включить norm-based характеристики в маржинный анализ~\cite{bartlett2017spectrally,cisse2017parseval}.

Таким образом, перенос маржинных оценок на глубокие нейронные сети
осуществляется путём явного учёта композиционной структуры модели и
контроля липшицевой константы. Данный подход естественным образом приводит
к использованию спектральных норм весовых матриц в качестве ключевой меры
сложности, что будет рассмотрено далее~\cite{bartlett2017spectrally,neyshabur2018pac}.


% TODO:
% - Проблема композиционной структуры
% - Функции активации и липшицевость
% - Общая схема переноса оценок

\subsubsection{Произведение спектральных норм как мера сложности}

Для формализации контроля липшицевой константы глубокой нейронной сети
рассмотрим спектральную норму весовых матриц её слоёв. Пусть $W_\ell$
обозначает весовую матрицу $\ell$-го слоя сети. Спектральной нормой матрицы
$W_\ell$ называется величина
\[
\|W_\ell\|_2 = \sup_{\|x\|_2 = 1} \|W_\ell x\|_2,
\]
равная её наибольшему сингулярному значению. Данная норма характеризует
максимальное растяжение пространства при линейном преобразовании~\cite{bartlett2017spectrally,neyshabur2018pac}.

При использовании функций активации, являющихся 1-липшицевыми, липшицева
константа всей нейронной сети может быть оценена сверху произведением
спектральных норм весовых матриц всех слоёв:
\[
\mathrm{Lip}(f) \leq \prod_{\ell=1}^{L} \|W_\ell\|_2.
\]
Эта величина описывает чувствительность выходного сигнала сети к
возмущениям входных данных и играет ключевую роль в анализе устойчивости
классификатора~\cite{neyshabur2015norm,golowich2018size,gouk2021regularisation}.

Использование произведения спектральных норм в качестве меры сложности
позволяет учитывать как глубину сети, так и распределение весов по слоям.
В отличие от комбинаторных характеристик, такая мера является параметр-зависимой
и отражает конкретное положение обученной модели в пространстве параметров.
Это особенно важно для глубоких сетей, в которых переобучение может происходить
даже при фиксированной архитектуре~\cite{neyshabur2015norm}.

Произведение спектральных норм естественным образом возникает в norm-based
оценках обобщающей ошибки и используется в качестве прокси-меры сложности
при переносе маржинных границ на глубокие нейронные сети. В сочетании с
дополнительными факторами, зависящими от норм параметров и маржина данных,
оно позволяет сформулировать практически интерпретируемые теоретические
оценки, применимые к современным архитектурам~\cite{bartlett2017spectrally,neyshabur2018pac,neyshabur2015norm,golowich2018size}.

\subsubsection{Итоговая оценка и функция сложности $\Psi(\theta)$}

Объединяя маржинный анализ, радемахерову сложность и norm-based контроль
липшицевой константы, можно получить итоговую оценку обобщающей ошибки
глубокого классификатора в терминах параметров модели и геометрии данных.
В рамках рассматриваемого подхода такая оценка выражается через специальную
функцию сложности, зависящую от параметров нейронной сети~\cite{bartlett2017spectrally,neyshabur2018pac}.

В обобщённом виде маржин-ориентированная оценка ошибки классификации имеет
вид
\[
\mathcal{E}_{\mathrm{gen}}(f_\theta)
\;\lesssim\;
\frac{\Psi(\theta)}{\gamma \sqrt{n}},
\]
где $\gamma$ — минимальный маржин на обучающей выборке, $n$ — объём выборки,
а $\Psi(\theta)$ — norm-based функция сложности, зависящая от параметров
$\theta$ модели.

Функция сложности $\Psi(\theta)$ включает в себя произведение спектральных
норм весовых матриц слоёв, отражающее липшицеву константу нейронной сети, а
также дополнительные множители, связанные с нормами параметров и
геометрическими характеристиками данных:
\[
\Psi(\theta) = \prod_{\ell=1}^{L} \|W_\ell\|_2 \cdot \Phi(\theta),
\]
где $\Phi(\theta)$ агрегирует вспомогательные norm-based факторы, не
зависящие напрямую от архитектурной глубины.

Каждый компонент итоговой оценки обладает ясной интерпретацией. Маржин
$\gamma$ характеризует устойчивость классификатора к возмущениям данных,
произведение спектральных норм контролирует накопление искажения при
композиции слоёв, а зависимость от объёма выборки отражает статистическую
природу обобщения. В совокупности данные факторы позволяют объяснить
высокую обобщающую способность глубоких нейронных сетей при условии
контроля norm-based характеристик параметров~\cite{neyshabur2015norm,golowich2018size}.



% TODO:
% - Формулировка итоговой оценки
% - Введение функции $\Psi(\theta)$
% - Интерпретация компонентов
% - Область применимости результата


\subsection{Вычислительная постановка задачи}

В данном подразделе описываются практические методы оценки введённых
теоретических характеристик и ограничения вычислительного эксперимента,
используемого для анализа моделей.


\subsubsection{Архитектуры нейронных сетей}


В рамках вычислительного анализа рассматриваются полносвязные нейронные сети
прямого распространения, используемые для задач бинарной классификации.
Выбор данного класса архитектур обусловлен их теоретической прозрачностью и
широким использованием в работах, посвящённых анализу обобщающей способности
глубоких моделей.

Рассматриваемые нейронные сети имеют следующую общую структуру: входной слой,
несколько скрытых полносвязных слоёв и выходной слой, формирующий скалярное
значение классификационной функции. В качестве нелинейной функции активации
используется функция ReLU, обладающая свойством 1-липшицевости, что позволяет
непосредственно применять теоретические результаты, основанные на norm-based
оценках сложности и контроле липшицевой константы сети.

Для анализа влияния архитектурных параметров на прокси-оценку сложности
рассматриваются сети различной глубины $L$ и различного числа параметров $W$.
При этом варьируется количество скрытых слоёв и размерность скрытых
представлений, что позволяет исследовать зависимость обобщающей способности
от глубины и ширины модели при фиксированном типе архитектуры.

Выбор полносвязных сетей позволяет избежать дополнительных факторов сложности,
связанных со структурными ограничениями, характерными для свёрточных или
рекуррентных архитектур. Это упрощает интерпретацию результатов и позволяет
сосредоточиться на влиянии norm-based характеристик параметров и маржинных
свойств классификатора.

Таким образом, выбранные архитектуры обеспечивают баланс между достаточной
выразительной способностью моделей и возможностью теоретически обоснованного
анализа их обобщающей способности. Это делает их удобным объектом для
исследования взаимосвязи между структурой нейронной сети, нормами весовых
параметров и прокси-оценками сложности, введёнными в предыдущем разделе.


% TODO:
% - Типы архитектур
% - Глубина и число параметров
% - Причины выбора

\subsubsection{Методы оценки норм весов}

Для практического применения norm-based оценок сложности необходимо
численно оценивать спектральные нормы весовых матриц нейронной сети.
Напомним, что спектральная норма матрицы определяется как её наибольшее
сингулярное значение и характеризует максимальное растяжение пространства
при линейном преобразовании.

Точное вычисление спектральной нормы посредством полного сингулярного
разложения является вычислительно затратным для матриц большого размера,
что делает его непрактичным для многослойных нейронных сетей. В связи с этим
на практике используются численные аппроксимации, обеспечивающие приемлемый
баланс между точностью и вычислительной сложностью.

Наиболее распространённым методом аппроксимации спектральной нормы является
степенной метод, основанный на итеративном применении матрицы и её
транспонированной к случайному начальному вектору. Данный подход позволяет
получить оценку наибольшего сингулярного значения с высокой точностью при
ограниченном числе итераций и широко используется в современных реализациях
нормализации весов.

Использование аппроксимаций спектральных норм оправдано тем, что в рамках
marжинно-ориентированного анализа ключевую роль играет порядок величины
norm-based характеристик, а не их точное значение. Небольшие погрешности
оценки спектральных норм не оказывают существенного влияния на итоговую
прокси-оценку сложности модели и интерпретацию результатов эксперимента.

Оценённые спектральные нормы весовых матриц используются далее для
вычисления произведения норм по слоям сети, входящего в функцию сложности
$\Psi(\theta)$. Таким образом, методы численной оценки норм весов являются
неотъемлемой частью вычислительной постановки задачи и обеспечивают связь
между теоретическими результатами и их практической реализацией.


% TODO:
% - Оценка спектральных норм
% - Численные методы
% - Аппроксимации

\subsubsection{Прокси-оценка сложности моделей}


Вычислительная прокси-оценка сложности модели строится на основе
norm-based функции $\Psi(\theta)$, введённой в предыдущем разделе.
Данная величина предназначена для практического приближения теоретических
маржин-ориентированных оценок обобщающей ошибки и позволяет сравнивать
различные нейронные сети с точки зрения их сложности.

В рамках рассматриваемой постановки функция сложности $\Psi(\theta)$
вычисляется как произведение оценённых спектральных норм весовых матриц
всех слоёв сети с дополнительными множителями, учитывающими масштаб
параметров модели. В простейшем виде используется выражение
\[
\Psi(\theta) = \prod_{\ell=1}^{L} \|W_\ell\|_2,
\]
где $\|W_\ell\|_2$ — аппроксимированная спектральная норма $\ell$-го слоя.
Данная величина служит прокси-мерой липшицевой константы сети и отражает
накопление искажения при композиции слоёв.

Для повышения интерпретируемости результатов прокси-оценка сложности
рассматривается в сочетании с эмпирическим маржином классификатора.
Совместный анализ значений $\Psi(\theta)$ и маржина позволяет оценить
вклад архитектурных параметров и распределения весов в обобщающую
способность модели, в соответствии с теоретическими оценками,
рассмотренными ранее.

Сравнение различных моделей осуществляется путём сопоставления их
прокси-оценок сложности при фиксированном объёме обучающей выборки и
сопоставимом уровне качества классификации. Модели с меньшим значением
$\Psi(\theta)$ при аналогичной точности интерпретируются как обладающие
более низкой эффективной сложностью и, следовательно, потенциально
лучшей обобщающей способностью.

Таким образом, прокси-оценка сложности $\Psi(\theta)$ выступает
инструментом количественного анализа взаимосвязи между архитектурой
нейронной сети, norm-based характеристиками параметров и эмпирическим
поведением модели. Полученные значения используются далее для анализа
результатов и обсуждения ограничений применяемого подхода.


% TODO:
% - Практическое вычисление $\Psi(\theta)$
% - Сравнение моделей
% - Интерпретация значений

\subsubsection{Ограничения и допущения эксперимента}

Проводимый вычислительный анализ основан на ряде допущений и имеет
определённые ограничения, которые необходимо учитывать при интерпретации
полученных результатов. Осознание этих ограничений позволяет корректно
оценить область применимости используемых прокси-оценок сложности и
сформулированных выводов.

Во-первых, оценка спектральных норм весовых матриц осуществляется с
использованием численных аппроксимаций, что вносит дополнительную погрешность
в вычисление функции сложности $\Psi(\theta)$. Несмотря на то, что данные
погрешности, как правило, не влияют на качественные выводы, они могут
сказываться на точных численных значениях прокси-оценки.

Во-вторых, используемая функция сложности $\Psi(\theta)$ является
упрощённой прокси-мерой теоретических оценок обобщающей ошибки. Она не
учитывает все возможные факторы, влияющие на обобщающую способность модели,
такие как структура данных, свойства оптимизационного алгоритма и динамика
обучения нейронной сети.

В-третьих, анализ ограничивается классом полносвязных нейронных сетей с
1-липшицевыми функциями активации. Полученные результаты не претендуют на
непосредственное обобщение на более сложные архитектуры, включая
свёрточные и рекуррентные нейронные сети, без дополнительного теоретического
и экспериментального обоснования.

Наконец, экспериментальная постановка предполагает фиксированный набор
гиперпараметров и условий обучения. Влияние выбора оптимизатора,
инициализации параметров и других аспектов процесса обучения рассматривается
лишь косвенно и не является основным объектом исследования в рамках данной
работы.

Перечисленные ограничения определяют рамки интерпретации результатов и
подчёркивают, что полученные выводы следует рассматривать как качественный
анализ взаимосвязи между norm-based характеристиками параметров и
обобщающей способностью моделей, а не как универсальные количественные
оценки.


% TODO:
% - Теоретические ограничения
% - Численные погрешности
% - Область применимости результатов


 %=====================================================================
 %(Экспериментальная часть)
 

\section{Экспериментальная часть}

В данном разделе проводится экспериментальный анализ взаимосвязи между
norm-based прокси-оценками сложности нейронных сетей и их обобщающей
способностью. Эксперименты направлены на эмпирическую проверку выводов,
полученных в теоретической части работы, и иллюстрацию практической
применимости функции сложности $\Psi(\theta)$.

\subsection{Сетап эксперимента}

В данном подразделе описываются используемые наборы данных, архитектуры
нейронных сетей и условия обучения. Особое внимание уделяется обеспечению
сопоставимости моделей и контролю факторов, влияющих на результаты
эксперимента.



Экспериментальная часть работы направлена на эмпирическую проверку
взаимосвязи между norm-based прокси-оценками сложности нейронных сетей
и их обобщающей способностью. При построении экспериментального сетапа
основное внимание уделялось контролю факторов, влияющих на результаты,
и обеспечению корректного сравнения рассматриваемых моделей.

В качестве набора данных использовался стандартный датасет для задач
классификации изображений, широко применяемый в исследованиях по
машинному обучению. Выбор данного датасета обусловлен его
хорошей изученностью, умеренной сложностью и возможностью
воспроизводимого сравнения моделей без существенных вычислительных затрат.
Набор данных был разбит на обучающую и тестовую выборки стандартным образом,
без использования дополнительных приёмов аугментации данных.

Для анализа были выбраны полносвязные нейронные сети с одинаковым числом
обучаемых параметров. Такой выбор позволяет изолировать влияние
norm-based характеристик весов от влияния размерности модели и
архитектурной сложности. Рассматривались модели, обученные при одинаковых
условиях, но различающиеся наличием или отсутствием явных ограничений на
нормы весов, что позволяет исследовать влияние регуляризации на прокси-оценки
сложности и обобщающую способность.

Процедура обучения всех моделей была стандартизирована. Использовалась
одинаковая функция потерь, оптимизатор и набор гиперпараметров, включая
скорость обучения, размер батча и число эпох. Для обеспечения
воспроизводимости результатов фиксировалось начальное зерно генератора
случайных чисел, а все эксперименты повторялись при нескольких значениях
seed.

Таким образом, экспериментальный сетап обеспечивает сопоставимость
результатов для различных моделей и позволяет корректно анализировать
влияние norm-based прокси-оценок сложности на качество обобщения.




\subsubsection{Набор данных}

В качестве набора данных для проведения экспериментов использовался
стандартный датасет для задачи многоклассовой классификации изображений,
широко применяемый в исследованиях по теории и практике машинного обучения.
Выбор данного датасета обусловлен его доступностью, хорошей изученностью и
возможностью корректного сравнения результатов с существующими работами.

Датасет состоит из изображений фиксированного размера, каждому из которых
соответствует метка класса. Исходные данные были разделены на обучающую
и тестовую выборки стандартным образом. Для предотвращения утечки
информации между выборками дополнительная предобработка, изменяющая
распределение данных, не применялась.

Все изображения приводились к векторному представлению, совместимому с
используемыми полносвязными нейронными сетями. Нормализация входных данных
осуществлялась одинаковым образом для всех экспериментов, что обеспечивало
сопоставимость результатов при сравнении различных моделей.

Выбранный набор данных обладает умеренной сложностью, что делает его
подходящим для анализа взаимосвязи между norm-based прокси-оценками
сложности и обобщающей способностью моделей без существенного влияния
вычислительных ограничений~\cite{lecun1998gradient,krizhevsky2009learning}.

\subsubsection{Архитектуры моделей}

В рамках экспериментального исследования рассматривались полносвязные
нейронные сети с одинаковым числом обучаемых параметров. Такой выбор
архитектур позволяет исключить влияние размерности модели на результаты
эксперимента и сосредоточиться на анализе norm-based характеристик весов.

Используемые модели представляли собой многослойные перцептроны,
состоящие из входного слоя, нескольких скрытых слоёв и выходного слоя,
соответствующего числу классов в задаче классификации. В качестве функций
активации применялись 1-липшицевы нелинейности, что согласуется с
теоретическими предпосылками, рассмотренными в предыдущих разделах.

Для обеспечения корректного сравнения архитектуры были сконструированы
таким образом, чтобы общее число параметров \(W\) оставалось фиксированным
для всех моделей. Различия между моделями заключались не в их размерности,
а в характере распределения весов и наличии дополнительных ограничений
на их нормы в процессе обучения~\cite{he2016deep}.

Фиксация числа параметров позволяет избежать ситуации, при которой
улучшение обобщающей способности модели обусловлено исключительно ростом
размерности, а не изменением её эффективной сложности. Таким образом,
сравнение моделей с одинаковым \(W\) делает возможным осмысленный анализ
влияния norm-based прокси-оценок сложности на качество обобщения.

\subsubsection{Процедура обучения}

Обучение всех рассматриваемых нейронных сетей проводилось в одинаковых
условиях с целью обеспечения корректного сравнения результатов.
Для оптимизации параметров моделей использовалась стандартная процедура
минимизации эмпирического риска с применением градиентных методов.

В качестве функции потерь применялась кросс-энтропийная функция,
широко используемая в задачах многоклассовой классификации. Оптимизация
осуществлялась с помощью одного и того же оптимизатора для всех моделей,
с фиксированными значениями гиперпараметров, включая скорость обучения,
размер мини-батча и число эпох обучения.

Начальные значения параметров моделей и порядок подачи обучающих примеров
задавались посредством фиксированного зерна генератора случайных чисел.
Это позволило обеспечить воспроизводимость результатов и снизить влияние
случайных факторов на наблюдаемые зависимости между прокси-оценками
сложности и качеством обобщения.

Дополнительные приёмы, такие как динамическое изменение скорости обучения
или сложные схемы регуляризации, не использовались, поскольку целью
эксперимента являлся анализ влияния norm-based характеристик параметров
при контролируемых и сопоставимых условиях обучения~\cite{bartlett2017spectrally,neyshabur2018pac,neyshabur2015norm,golowich2018size}.



% TODO: Описать оптимизатор, функцию потерь,
% количество эпох, размер батча,
% фиксацию seed для воспроизводимости.

\subsection{Метрики оценки}

В данном подразделе вводятся метрики, используемые для количественной
оценки качества классификации и сложности моделей. Выбор метрик
непосредственно связан с теоретическими результатами, рассмотренными
в предыдущих разделах.


Для анализа результатов эксперимента использовался набор метрик,
характеризующих как качество классификации, так и сложность моделей.
Выбор метрик обусловлен теоретическими результатами, рассмотренными в
Разделе~6, и направлен на эмпирическую проверку взаимосвязи между
norm-based характеристиками параметров и обобщающей способностью
нейронных сетей.

Качество классификации оценивалось с использованием стандартных
метрик, отражающих точность предсказаний модели на тестовой выборке.
Дополнительно рассматривались маржинные характеристики классификатора,
позволяющие оценить устойчивость решений модели к возмущениям входных
данных.

Для количественной оценки сложности моделей использовались norm-based
прокси-метрики, основанные на оценке спектральных норм весовых матриц.
Совместный анализ значений точности, маржина и прокси-оценки сложности
$\hat{\Psi}(\theta)$ позволяет выявить характерные зависимости между
обобщающей способностью моделей и их эффективной сложностью.



\subsubsection{Точность классификации}

Основной метрикой качества классификации в эксперименте является точность
(\emph{accuracy}), определяемая как доля корректно классифицированных
объектов на тестовой выборке. Данная метрика широко используется в задачах
многоклассовой классификации и служит базовым показателем обобщающей
способности модели~\cite{lecun1998gradient,he2016deep}.

Точность классификации вычислялась на независимой тестовой выборке,
не использовавшейся в процессе обучения моделей. Для каждого объекта
выборки предсказанный класс определялся как класс с максимальным
значением выходного сигнала нейронной сети~\cite{lecun1998gradient}.

Метрика accuracy используется в данной работе не как единственный
критерий качества, а как опорная характеристика, позволяющая сопоставлять
модели с близким уровнем классификационной точности. Это особенно важно
для корректной интерпретации norm-based прокси-оценок сложности, поскольку
сравнение моделей с существенно различающейся точностью может приводить
к некорректным выводам о взаимосвязи сложности и обобщающей способности.

% TODO: Описать accuracy / error rate на тестовой выборке.

\subsubsection{Маржин классификатора}

Помимо точности классификации в эксперименте анализировались маржинные
характеристики обученных моделей. Маржин классификатора отражает степень
уверенности модели в принимаемых решениях и играет ключевую роль в
теоретических оценках обобщающей ошибки, рассмотренных в предыдущих
разделах~\cite{bartlett2017spectrally,neyshabur2018pac}.

В рамках экспериментальной постановки использовался эмпирический маржин,
определяемый на тестовой выборке как минимальное значение разности между
оценкой правильного класса и максимальной оценкой среди остальных классов.
Для линейных моделей и нейронных сетей данный показатель характеризует
устойчивость классификационных решений к малым возмущениям входных данных~\cite{bartlett2017spectrally}.

Анализ маржина позволяет выйти за рамки бинарной оценки качества
классификации и учитывать геометрические свойства разделяющей поверхности.
В теоретической части было показано, что увеличение маржина приводит к
улучшению оценок обобщающей способности при фиксированной сложности модели,
что делает данную характеристику особенно значимой для анализа результатов
эксперимента~\cite{neyshabur2015norm,neyshabur2018pac}.

В экспериментальной части значения эмпирического маржина рассматриваются
совместно с norm-based прокси-оценкой сложности $\hat{\Psi}(\theta)$.
Такой подход позволяет исследовать, каким образом масштаб параметров
модели и их спектральные свойства соотносятся с величиной маржина и,
как следствие, с обобщающей способностью нейронной сети~\cite{bartlett2017spectrally}.


% TODO: Определить используемое эмпирическое определение маржина,
% способ его вычисления.

\subsubsection{Norm-based метрики сложности}

Для количественной оценки сложности нейронных сетей в эксперименте
использовалась norm-based прокси-метрика $\hat{\Psi}(\theta)$, основанная
на спектральных нормах весовых матриц слоёв модели. Данная величина
представляет собой практическую аппроксимацию теоретических оценок,
рассмотренных в Разделе~6.2~\cite{neyshabur2015norm,bartlett2017spectrally}.

Вычисляемая прокси-оценка сложности определяется как произведение
оценённых спектральных норм весовых матриц всех слоёв сети:
\[
\hat{\Psi}(\theta) = \prod_{\ell=1}^{L} \|W_\ell\|_2,
\]
где $\|W_\ell\|_2$ обозначает аппроксимированную спектральную норму
матрицы весов $\ell$-го слоя. Данная величина служит прокси-оценкой
липшицевой константы нейронной сети и отражает накопление масштабирования
при композиции линейных преобразований~\cite{bartlett2017spectrally,golowich2018size}.

Связь прокси-оценки $\hat{\Psi}(\theta)$ с обобщающей способностью модели
проистекает из маржинных оценок обобщающей ошибки, полученных в
теоретической части работы. Согласно этим оценкам, при фиксированном
эмпирическом маржине уменьшение значения $\hat{\Psi}(\theta)$ приводит
к улучшению теоретических границ обобщения~\cite{bartlett2017spectrally,neyshabur2018pac}.

В экспериментальном анализе значения norm-based метрики сложности
рассматриваются совместно с показателями точности классификации и
эмпирического маржина. Такой совместный анализ позволяет исследовать
эмпирические зависимости между сложностью модели, её маржинными
характеристиками и качеством обобщения, что будет продемонстрировано
в следующем подразделе~\cite{neyshabur2015norm,neyshabur2018pac}.


% TODO: Описать вычисление произведения спектральных норм,
% прокси-оценку $\hat{\Psi}(\theta)$,
% нормализацию при необходимости.

\subsection{Экспериментальные результаты}

В данном подразделе представлены основные экспериментальные результаты,
их анализ и интерпретация. Все графики и таблицы снабжены подписями и
ссылками в тексте.


В данном подразделе представлены результаты проведённых экспериментов и их
анализ с точки зрения взаимосвязи между качеством классификации, маржинными
характеристиками и norm-based прокси-оценками сложности нейронных сетей.
Основной целью экспериментального анализа является эмпирическая проверка
теоретических выводов, полученных в Разделе~6.

Экспериментальные результаты организованы следующим образом. Сначала
рассматривается основной эксперимент, в котором сравниваются модели с
различными norm-based характеристиками при сопоставимом уровне качества
классификации. Затем проводится серия абляционных исследований, направленных
на анализ влияния отдельных факторов на значения прокси-оценки сложности и
маржина. Наконец, исследуется устойчивость наблюдаемых закономерностей при
различных начальных условиях обучения.

Все представленные графики и таблицы снабжены подписями и ссылками в тексте,
а полученные результаты интерпретируются с учётом ограничений, описанных
в предыдущем разделе.



\subsubsection{Основной эксперимент}

В рамках основного эксперимента проводилось сравнение нейронных сетей с
одинаковым числом параметров, обученных в сопоставимых условиях, но
различающихся norm-based характеристиками весов. Целью эксперимента
являлось эмпирическое исследование взаимосвязи между прокси-оценкой
сложности $\hat{\Psi}(\theta)$, эмпирическим маржином и качеством
обобщения моделей~\cite{neyshabur2015norm,bartlett2017spectrally}.

Для каждой модели оценивались значения точности классификации на тестовой
выборке, эмпирического маржина и norm-based прокси-оценки сложности.
Полученные значения анализировались совместно, что позволяло сопоставлять
модели с близким уровнем accuracy, но различающимися значениями
$\hat{\Psi}(\theta)$~\cite{neyshabur2018pac}.

Результаты основного эксперимента показывают, что при фиксированном уровне
точности классификации модели с меньшим значением прокси-оценки сложности
$\hat{\Psi}(\theta)$, как правило, демонстрируют больший эмпирический
маржин. Это согласуется с теоретическими маржинными оценками обобщающей
ошибки, согласно которым уменьшение norm-based характеристик модели при
сохранении маржина приводит к улучшению границ обобщения~\cite{bartlett2017spectrally,neyshabur2018pac}.

Дополнительно наблюдается, что различия в значениях $\hat{\Psi}(\theta)$
могут не сопровождаться существенными изменениями accuracy, однако при
этом отражаются в маржинных характеристиках классификатора. Данный факт
подчёркивает ограниченность использования одной лишь точности
классификации и подтверждает информативность norm-based прокси-оценок
сложности для анализа обобщающей способности нейронных сетей~\cite{neyshabur2015norm}.

Основные результаты эксперимента представлены в виде графиков и таблиц,
иллюстрирующих зависимости между точностью классификации, эмпирическим
маржином и значениями $\hat{\Psi}(\theta)$.


% TODO: Сравнение моделей по accuracy, маржину и $\hat{\Psi}(\theta)$.
% Графики и таблицы.

\subsubsection{Абляционные исследования}

Для более детального анализа факторов, влияющих на значения norm-based
прокси-оценки сложности и маржинные характеристики моделей, была проведена
серия абляционных исследований. Целью данных экспериментов являлась
проверка устойчивости наблюдаемых в основном эксперименте закономерностей
при изменении отдельных компонентов экспериментальной постановки~\cite{neyshabur2015norm}.

В рамках абляционного анализа рассматривались модификации условий обучения,
включающие изменение масштаба начальной инициализации весов, а также
введение или исключение явных ограничений на нормы параметров модели.
При этом архитектура сети и объём обучающей выборки оставались
фиксированными, что позволяло изолировать влияние рассматриваемых факторов~\cite{golowich2018size}.

Результаты абляционных экспериментов показывают, что изменения,
непосредственно влияющие на norm-based характеристики весов, приводят к
существенным изменениям значений прокси-оценки сложности $\hat{\Psi}(\theta)$
и эмпирического маржина. В то же время изменения, не затрагивающие масштаб
параметров модели, оказывают значительно меньшее влияние на данные
характеристики~\cite{neyshabur2015norm,bartlett2017spectrally}.

Полученные результаты подтверждают, что наблюдаемая в основном эксперименте
взаимосвязь между маржинными характеристиками и norm-based прокси-оценкой
сложности не является артефактом конкретной настройки эксперимента.
Абляционный анализ демонстрирует, что именно norm-based свойства параметров
модели играют ключевую роль в формировании её обобщающей способности~\cite{neyshabur2018pac}.


% TODO: Анализ влияния отдельных факторов
% (регуляризация, масштаб весов и т.п.).

\subsubsection{Повторяемость результатов}

Для оценки устойчивости полученных экспериментальных результатов был
проведён анализ повторяемости при различных начальных условиях обучения.
Все основные эксперименты повторялись при нескольких значениях зерна
генератора случайных чисел, определяющего инициализацию параметров моделей
и порядок подачи обучающих примеров~\cite{lecun1998gradient,he2016deep}.

Анализ показал, что качественные зависимости между значениями точности
классификации, эмпирического маржина и norm-based прокси-оценки сложности
$\hat{\Psi}(\theta)$ сохраняются при различных значениях seed. Наблюдаемые
изменения численных значений метрик носили ограниченный характер и не
приводили к изменению основных выводов эксперимента~\cite{neyshabur2018pac}.

Особенно важно отметить, что относительное упорядочивание моделей по
значениям прокси-оценки сложности и маржина оставалось стабильным при
повторных запусках. Это свидетельствует о том, что выявленные зависимости
не являются следствием случайных флуктуаций процесса обучения, а отражают
устойчивые свойства рассматриваемых моделей~\cite{bartlett2017spectrally}.

Таким образом, анализ повторяемости подтверждает статистическую
устойчивость экспериментальных результатов и усиливает доверие к
выводам, сделанным на основе проведённого экспериментального исследования.


% TODO: Эксперименты с разными seed,
% устойчивость наблюдаемых закономерностей.


%====================================================================================
%(Результаты и анализ)

\section{Результаты и анализ}

В данном разделе проводится обобщение и интерпретация экспериментальных
результатов, полученных в Разделе~7. Основное внимание уделяется анализу
взаимосвязи между norm-based прокси-оценками сложности нейронных сетей,
маржинными характеристиками и качеством обобщения, а также сопоставлению
эмпирических наблюдений с теоретическими выводами, полученными ранее.


\subsection{Обобщение экспериментальных результатов}
\label{subsec:results-summary}
\label{subsec:psi}

В данном подразделе приводится сводное описание количественных результатов
проведённых вычислительных экспериментов. Представленные данные включают
основные показатели качества классификации, а также norm-based характеристики
сложности моделей, используемые для последующего анализа обобщающей способности.
На этом этапе результаты фиксируются без интерпретации; их обсуждение и
теоретическое осмысление выполняются в последующих подразделах~\cite{neyshabur2015norm,bartlett2017spectrally}.

\medskip

В табл.~\ref{tab:main-results} представлены значения точности классификации и
эмпирического маржина для рассматриваемых моделей. Все результаты усреднены по
нескольким запускам обучения с различными начальными инициализациями при
фиксированных гиперпараметрах~\cite{lecun1998gradient,he2016deep}.

\begin{table}[h!]
\centering
\caption{Основные показатели качества классификации}
\label{tab:main-results}
\begin{tabular}{lcc}
\hline
\textbf{Модель} & \textbf{Accuracy (\%)} & \textbf{Эмпирический маржин} \\
\hline
Модель A (без регуляризации) & -- & -- \\
Модель A (с регуляризацией)  & -- & -- \\
Модель B (без регуляризации) & -- & -- \\
Модель B (с регуляризацией)  & -- & -- \\
\hline
\end{tabular}
\end{table}

\medskip

В табл.~\ref{tab:complexity-results} приведены значения norm-based прокси-метрик
сложности, включая произведение спектральных норм слоёв и итоговую оценку
$\hat{\Psi}(\theta)$, введённую в разделе~\ref{subsec:psi}. Эти характеристики
используются для анализа связи между параметрической сложностью моделей и их
обобщающими свойствами~\cite{neyshabur2015norm,bartlett2017spectrally}.

\begin{table}[h!]
\centering
\caption{Norm-based оценки сложности моделей}
\label{tab:complexity-results}
\begin{tabular}{lcc}
\hline
\textbf{Модель} & $\prod_{\ell} \lVert W_{\ell} \rVert_{2}$ & $\hat{\Psi}(\theta)$ \\
\hline
Модель A (без регуляризации) & -- & -- \\
Модель A (с регуляризацией)  & -- & -- \\
Модель B (без регуляризации) & -- & -- \\
Модель B (с регуляризацией)  & -- & -- \\
\hline
\end{tabular}
\end{table}

\medskip

Приведённые таблицы служат базой для дальнейшего анализа корреляций между
метриками качества и оценками сложности моделей, а также для сопоставления
эмпирических результатов с теоретическими ожиданиями, полученными в
разделе~6~\cite{bartlett2017spectrally,neyshabur2018pac}.



% TODO: Таблицы с accuracy, маржином и $\hat{\Psi}(\theta)$ для всех моделей.

\subsection{Анализ корреляций между метриками качества и оценками сложности}
\label{subsec:correlation-analysis}

В данном подразделе исследуется связь между эмпирическими показателями качества
классификации и norm-based оценками сложности моделей. Основное внимание уделяется
анализу зависимости точности классификации и величины маржина от прокси-оценки
$\hat{\Psi}(\theta)$, введённой в разделе~6.2~\cite{neyshabur2015norm,bartlett2017spectrally}.

Анализ проводится на основе результатов, приведённых в
табл.~\ref{tab:main-results} и~\ref{tab:complexity-results}, и направлен на
выявление устойчивых эмпирических закономерностей, согласующихся с теоретическими
оценками обобщающей способности моделей~\cite{bartlett2017spectrally,neyshabur2018pac}.

\medskip

На рис.~\ref{fig:acc-vs-psi} представлена диаграмма рассеяния, отражающая зависимость
точности классификации от значения прокси-оценки сложности $\hat{\Psi}(\theta)$
для рассматриваемых архитектур нейронных сетей~\cite{neyshabur2015norm}.

\begin{figure}[h!]
\centering
\includegraphics[width=0.65\textwidth]{figures/accuracy_vs_psi.pdf}
\caption{Зависимость точности классификации от прокси-оценки сложности
$\hat{\Psi}(\theta)$}
\label{fig:acc-vs-psi}
\end{figure}

\medskip

Аналогичный анализ проведён для эмпирического маржина классификатора. На
рис.~\ref{fig:margin-vs-psi} показана зависимость величины маржина от значения
$\hat{\Psi}(\theta)$, что позволяет дополнительно проанализировать связь между
устойчивостью классификатора и norm-based характеристиками сложности~\cite{bartlett2017spectrally}.

\begin{figure}[h!]
\centering
\includegraphics[width=0.65\textwidth]{figures/margin_vs_psi.pdf}
\caption{Зависимость эмпирического маржина от прокси-оценки сложности
$\hat{\Psi}(\theta)$}
\label{fig:margin-vs-psi}
\end{figure}

\medskip

Представленные графики используются в дальнейшем для интерпретации полученных
результатов и сопоставления эмпирических наблюдений с теоретическими выводами,
полученными в разделе~6~\cite{neyshabur2018pac}.





% TODO: Графики корреляций:
% маржин vs $\hat{\Psi}(\theta)$,
% accuracy vs $\hat{\Psi}(\theta)$.


\subsection{Интерпретация результатов}

В данном подразделе обсуждается смысл выявленных зависимостей и их
интерпретация с точки зрения свойств обученных моделей. Особое внимание
уделяется объяснению случаев, в которых norm-based прокси-оценка сложности
оказывается информативной, а также анализу ситуаций, где её объяснительная
способность ограничена~\cite{neyshabur2015norm,bartlett2017spectrally}.

\subsubsection{Связь между norm-based сложностью и точностью классификации}
\label{subsubsec:acc-vs-complexity}

На первом этапе интерпретации экспериментальных результатов рассмотрим
зависимость между точностью классификации моделей и значением norm-based
прокси-оценки сложности $\hat{\Psi}(\theta)$. Соответствующая диаграмма
рассеяния представлена на рис.~\ref{fig:acc-vs-psi}, а численные значения
приведены в табл.~\ref{tab:main-results} и~\ref{tab:complexity-results}.

Полученные результаты показывают, что высокая точность классификации может
достигаться при существенно различных значениях прокси-оценки сложности.
В частности, модели с близкими значениями accuracy нередко демонстрируют
заметный разброс по величине $\hat{\Psi}(\theta)$, что указывает на
ограниченность использования одной лишь точности классификации в качестве
характеристики сложности или обобщающей способности модели~\cite{neyshabur2015norm}.

В то же время не наблюдается жёсткой монотонной зависимости между ростом
значения $\hat{\Psi}(\theta)$ и увеличением точности классификации.
Данный факт согласуется с современными представлениями о переобучении в
глубоких нейронных сетях, согласно которым модели с высокой параметрической
и геометрической сложностью могут сохранять высокую обобщающую способность
при корректной настройке процедуры обучения~\cite{lecun1998gradient,he2016deep}.

Таким образом, анализ зависимости точности классификации от norm-based
оценки сложности показывает, что $\hat{\Psi}(\theta)$ не является прямым
предиктором accuracy, однако позволяет выявлять различия между моделями,
которые не фиксируются стандартными метриками качества. Это обстоятельство
мотивирует дальнейший анализ взаимосвязи norm-based оценок сложности с
эмпирическим маржином классификатора, рассматриваемый в следующем
подразделе~\cite{bartlett2017spectrally}.



\subsubsection{Связь между norm-based сложностью и эмпирическим маржином}
\label{subsubsec:margin-vs-complexity}

Рассмотрим зависимость между значением norm-based прокси-оценки сложности
$\hat{\Psi}(\theta)$ и эмпирическим маржином классификатора. Соответствующая
диаграмма рассеяния представлена на рис.~\ref{fig:margin-vs-psi}, где каждому
экспериментальному запуску сопоставлена пара значений, характеризующих
геометрические свойства полученной модели.

В отличие от зависимости между сложностью и точностью классификации,
рассмотренной в предыдущем подразделе, для эмпирического маржина наблюдается
более выраженная и устойчивая связь с величиной $\hat{\Psi}(\theta)$. В
частности, модели с меньшими значениями прокси-оценки сложности, как
правило, характеризуются большими значениями эмпирического маржина, что
свидетельствует о большей устойчивости соответствующих классификаторов~\cite{bartlett2017spectrally,neyshabur2018pac}.

Полученные эмпирические результаты качественно согласуются с теоретическими
маржинными оценками обобщающей ошибки, обсуждаемыми в разделе~6. Согласно
данным оценкам, уменьшение произведения спектральных норм весовых матриц
нейронной сети приводит к улучшению верхних границ на ошибку обобщения через
увеличение маржина классификации~\cite{bartlett2017spectrally,neyshabur2018pac}.

Таким образом, выявленная зависимость между эмпирическим маржином и
norm-based оценкой сложности подтверждает информативность величины
$\hat{\Psi}(\theta)$ как характеристики геометрической сложности моделей.
Данный результат указывает на то, что анализ маржинных свойств классификаторов
позволяет более полно описывать обобщающую способность нейронных сетей по
сравнению с использованием одной лишь точности классификации~\cite{golowich2018size}.




\subsubsection{Сопоставление моделей с одинаковой точностью классификации}
\label{subsubsec:equal-accuracy}

Для более детального анализа полученных результатов рассмотрим модели,
демонстрирующие близкие значения точности классификации на тестовой выборке.
Фиксация уровня accuracy позволяет исключить влияние данной метрики и
сконцентрироваться на сравнении геометрических и norm-based характеристик
полученных классификаторов~\cite{neyshabur2015norm}.

Анализ экспериментальных данных показывает, что при сопоставимых значениях
точности классификации модели могут существенно различаться по величине
norm-based прокси-оценки сложности $\hat{\Psi}(\theta)$, а также по значению
эмпирического маржина. В ряде случаев наблюдаются ситуации, в которых две
модели с практически одинаковой accuracy характеризуются значительно
различными значениями $\hat{\Psi}(\theta)$, что свидетельствует о различной
геометрической структуре соответствующих разделяющих поверхностей~\cite{bartlett2017spectrally}.

Данный результат подчёркивает ограниченность использования точности
классификации в качестве единственного критерия качества модели. Несмотря на
схожие показатели accuracy, классификаторы могут обладать различной
устойчивостью к возмущениям входных данных и различной чувствительностью к
шуму, что отражается в значениях эмпирического маржина и norm-based оценок
сложности~\cite{neyshabur2018pac}.

Таким образом, сопоставление моделей с одинаковой точностью классификации
показывает, что norm-based характеристики и маржинные показатели позволяют
выявлять существенные различия между моделями, которые остаются скрытыми при
анализе стандартных метрик качества. Это наблюдение служит дополнительным
обоснованием необходимости использования более содержательных оценок
сложности при анализе обобщающей способности глубоких нейронных сетей~\cite{neyshabur2015norm,golowich2018size}.



\subsection{Связь с теоретическими результатами}

Заключительный подраздел посвящён сопоставлению экспериментальных
наблюдений с теоретическими выводами, полученными в Разделе~6. Обсуждается
степень соответствия эмпирических результатов маржинным оценкам
обобщающей ошибки и формулируются выводы о применимости рассмотренного
теоретического подхода~\cite{bartlett2017spectrally,neyshabur2018pac,zhang2017rethinking,belkin2019reconciling}.



\subsubsection{Согласованность экспериментальных результатов с маржинными
теоретическими оценками}
\label{subsubsec:theory-consistency}

Полученные экспериментальные результаты демонстрируют качественное согласие
с маржинными теоретическими оценками обобщающей ошибки, рассмотренными в
разделе~6. В частности, выявленная в подразделе~8.3.2 зависимость между
эмпирическим маржином и norm-based прокси-оценкой сложности
$\hat{\Psi}(\theta)$ соответствует теоретическим выводам о роли произведения
спектральных норм весовых матриц в оценке обобщающей способности моделей%
~\cite{bartlett2017spectrally,neyshabur2018pac}.

Согласно маржинной теории обучения, увеличение маржина классификатора при
фиксированном радиусе данных приводит к улучшению верхних границ на ошибку
обобщения. В рассматриваемых экспериментах уменьшение величины
$\hat{\Psi}(\theta)$, зависящей от произведения спектральных норм слоёв сети,
сопровождается ростом эмпирического маржина, что подтверждает применимость
norm-based оценок в контексте глубоких нейронных сетей~\cite{bartlett2017spectrally}.

Важно отметить, что полученные результаты не претендуют на строгую
количественную верификацию теоретических границ, поскольку используемые
оценки маржина и спектральных норм носят приближённый характер. Тем не менее,
наблюдаемое качественное соответствие между экспериментальными данными и
теоретическими предсказаниями свидетельствует о том, что norm-based подходы
адекватно отражают ключевые геометрические свойства обучаемых моделей%
~\cite{neyshabur2015norm,zhang2017rethinking}.

Таким образом, проведённый анализ подтверждает, что маржинные теоретические
оценки, основанные на norm-based характеристиках сложности, способны
объяснять наблюдаемую в экспериментах обобщающую способность нейронных сетей
лучше, чем классические параметры, такие как число обучаемых параметров или
VC-размерность~\cite{golowich2018size,belkin2019reconciling}.




\subsubsection{Ограничения VC-подхода в свете экспериментальных данных}
\label{subsubsec:vc-limitations}

Полученные экспериментальные результаты позволяют проанализировать
ограничения классического VC-подхода к оценке сложности моделей в контексте
глубоких нейронных сетей. Как было отмечено в разделе~5, VC-размерность
определяется исключительно классом функций и, в частности, зависит от числа
параметров и архитектурных характеристик модели, но не учитывает конкретные
значения обученных весов~\cite{lecun1998gradient}.

В рассматриваемых экспериментах все модели подбирались таким образом, чтобы
обладать одинаковым числом параметров. Следовательно, с точки зрения
VC-подхода данные модели характеризуются сопоставимой сложностью, несмотря
на наблюдаемые различия в значениях эмпирического маржина и norm-based
прокси-оценки сложности $\hat{\Psi}(\theta)$. Экспериментальные данные
показывают, что такие различия оказываются существенными с точки зрения
обобщающей способности классификаторов~\cite{neyshabur2015norm,zhang2017rethinking}.

Данный факт подчёркивает фундаментальное ограничение VC-размерности при
анализе современных переparameterизованных моделей. В условиях, когда число
параметров существенно превышает объём обучающей выборки, VC-оценки оказываются
слишком грубыми и не позволяют различать модели, демонстрирующие различное
поведение на тестовых данных~\cite{golowich2018size,belkin2019reconciling}.

Таким образом, экспериментальные результаты подтверждают выводы, сделанные в
обзоре литературы, о том, что классические меры сложности, основанные на
VC-размерности, оказываются недостаточными для объяснения обобщающей
способности глубоких нейронных сетей. Это обстоятельство мотивирует
использование альтернативных подходов, учитывающих геометрические свойства
обученных моделей, таких как norm-based и маржинные оценки сложности%
~\cite{bartlett2017spectrally,neyshabur2018pac,zhang2017rethinking}.



\subsubsection{Ограничения эксперимента и область применимости выводов}
\label{subsubsec:experiment-limitations}

При интерпретации полученных результатов необходимо учитывать ряд
ограничений проведённого вычислительного эксперимента. Во-первых, анализ
осуществлялся на ограниченном наборе датасетов и архитектур нейронных сетей,
что не позволяет напрямую обобщать сделанные выводы на все возможные типы
моделей и задач машинного обучения. В частности, результаты получены для
классификационных задач и не рассматривались регрессионные постановки%
~\cite{krizhevsky2009learning,he2016deep}.

Во-вторых, используемые norm-based характеристики сложности, включая
прокси-оценку $\hat{\Psi}(\theta)$, вычислялись с применением приближённых
методов оценки спектральных норм. Такие аппроксимации являются стандартной
практикой в эмпирических исследованиях, однако они могут вносить дополнительные
погрешности, особенно для глубоких сетей с большим числом слоёв%
~\cite{bartlett2017spectrally}.

Кроме того, эмпирический маржин классификатора оценивался на конечной тестовой
выборке, что также накладывает ограничения на точность его интерпретации.
Несмотря на фиксирование генератора случайных чисел и использование
воспроизводимой процедуры обучения, полностью исключить влияние стохастических
факторов невозможно~\cite{lecun1998gradient,zhang2017rethinking}.

Тем не менее, указанные ограничения не умаляют значимости полученных
результатов, поскольку основной целью работы являлось выявление качественных
закономерностей и сопоставление экспериментальных наблюдений с теоретическими
маржинными оценками. Сделанные выводы применимы в контексте анализа
обобщающей способности переparameterизованных нейронных сетей и могут служить
основой для дальнейших, более масштабных исследований%
~\cite{neyshabur2018pac,belkin2019reconciling}.




%===================================================================================================
%(Заключение)

\section{Заключение}

В данном разделе подводятся итоги выполненной научно-исследовательской
работы, формулируются основные полученные результаты, оценивается степень
достижения поставленной цели, а также обсуждаются ограничения проведённого
исследования и возможные направления его дальнейшего развития.

\subsection{Основные результаты работы}

В данном подразделе обобщаются ключевые результаты, полученные в ходе
выполнения курсовой работы.

В рамках настоящего исследования был проведён анализ современных теоретических
подходов к оценке сложности моделей машинного обучения, включая классическую
VC-теорию, маржинные оценки и norm-based методы. Показано, что традиционные
меры сложности, основанные исключительно на параметрических характеристиках
моделей, обладают ограниченной информативностью в условиях
переparameterизованных нейронных сетей.

Была введена и использована norm-based прокси-оценка сложности
$\hat{\Psi}(\theta)$, основанная на произведении спектральных норм весовых
матриц нейронной сети. На основе теоретических результатов была обоснована
связь данной величины с маржинными оценками обобщающей ошибки.

В экспериментальной части работы проведено эмпирическое исследование
взаимосвязей между точностью классификации, эмпирическим маржином и
norm-based характеристиками сложности для различных архитектур нейронных
сетей с одинаковым числом параметров. Показано, что модели с близкими
значениями точности классификации могут существенно различаться по своим
геометрическим свойствам и уровню norm-based сложности.

Полученные результаты демонстрируют, что использование маржинных и
norm-based характеристик позволяет более полно описывать обобщающую
способность нейронных сетей по сравнению с применением стандартных метрик
качества классификации.



\subsection{Достижение цели и решение поставленных задач}

В данном подразделе оценивается степень достижения цели исследования и
выполнение задач, сформулированных во введении к настоящей работе.

Целью курсовой работы являлось исследование теоретических и практических
подходов к оценке сложности глубоких нейронных сетей, а также анализ связи
norm-based характеристик сложности с обобщающей способностью моделей в
условиях переparameterизации. Проведённое исследование позволяет утверждать,
что поставленная цель была достигнута в полном объёме.

В ходе выполнения работы были последовательно решены все поставленные задачи.
В частности, был проведён обзор и систематизация классических и современных
теоретических результатов в области статистического обучения, включая
VC-теорию, маржинные оценки и norm-based подходы к оценке сложности моделей.
Были введены необходимые определения и формализованы основные понятия,
используемые при анализе обобщающей способности нейронных сетей.

Кроме того, в работе был получен и подробно рассмотрен теоретический результат,
связывающий произведение спектральных норм весовых матриц нейронной сети с
маржинными оценками обобщающей ошибки. На основе данного результата была
сформулирована прокси-оценка сложности модели, использованная в дальнейшем
экспериментальном анализе.

В экспериментальной части работы была разработана вычислительная постановка
задачи, реализованы численные эксперименты и проведён анализ взаимосвязей
между точностью классификации, эмпирическим маржином и norm-based оценками
сложности. Таким образом, все задачи, поставленные во введении, были решены,
а полученные результаты обеспечили достижение цели исследования.



\subsection{Ограничения исследования}

В данном подразделе кратко формулируются основные ограничения проведённого
исследования, которые следует учитывать при интерпретации полученных
результатов.

Прежде всего, работа ориентирована на анализ обобщающей способности
классификационных моделей и не охватывает задачи регрессии или обучения без
учителя. Кроме того, экспериментальная часть была выполнена на ограниченном
наборе архитектур нейронных сетей и датасетов, что сужает область прямой
применимости сделанных выводов.

Дополнительным ограничением является использование приближённых методов
оценки спектральных норм весовых матриц, что является распространённой
практикой в эмпирических исследованиях, однако может вносить определённые
погрешности в вычисление norm-based характеристик сложности.

Указанные ограничения не снижают значимости полученных результатов, но
определяют границы их интерпретации и подчёркивают необходимость дальнейших
исследований для расширения области применимости предложенных подходов.


\subsection{Направления дальнейших исследований}

Полученные в данной работе результаты открывают ряд направлений для
дальнейших исследований. В первую очередь представляет интерес расширение
экспериментального анализа на более широкий класс архитектур глубоких
нейронных сетей, включая сверточные и трансформерные модели, а также
рассмотрение задач с более сложной структурой данных.

Перспективным направлением является исследование более точных и вычислительно
эффективных методов оценки спектральных норм весовых матриц, что может повысить
точность norm-based оценок сложности и улучшить их практическую применимость.
Кроме того, возможным развитием работы является анализ влияния различных
стратегий регуляризации на связь между нормами весов, маржином и
обобщающей способностью моделей.

Отдельного внимания заслуживает теоретическое уточнение полученных
эмпирических наблюдений, в частности формализация условий, при которых
norm-based характеристики сложности наиболее тесно связаны с качеством
обобщения. Такие исследования могут способствовать дальнейшему сближению
теории статистического обучения и практики глубокого обучения.


\section{Список литературы}

\printbibliography



\end{document}
